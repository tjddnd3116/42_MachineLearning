{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ac09b7",
   "metadata": {},
   "source": [
    "## 확률적 경사 하강법\n",
    "\n",
    "### 경사하강법 알고리즘을 이해하고 대량의 데이터에서 분류 모델을 훈련하는 방법을 배웁니다.\n",
    "\n",
    "## 점진적인 학습\n",
    "\n",
    "만약 수산물이 계속 추가 된다고 할때 도착하는 대로 가능한 즉시 훈련 데이터를 만든다면 어느 생선이 먼저 올지, 모든 생선이 도착할 때까지 기다릴 수도 없다.\n",
    "\n",
    "어떻게 해야 할까?\n",
    "\n",
    "지금의 문제는 훈련 데이터가 조금씩 전달된다는 것이다.\n",
    "\n",
    "그럼 기본의 훈련 데이터에 새로운 데이터를 추가하여 모델을 다시 훈련하면 어떨까??\n",
    "\n",
    "그렇게 하면 시간이 지날수록 데이터가 늘어난다는 문제점이 있다.\n",
    "\n",
    "그러면 이전 데이터를 버림으로써 훈련 데이터의 크기를 일정하게 유지하면 어떨까??\n",
    "\n",
    "그렇게 하면 버린 데이터에 중요한 생선 데이터가 포함되어 있으면 큰일이다.\n",
    "\n",
    "그럼 훈련한 모델을 버리지 않고 새로운 데이터에 대해서만 조금씩 더 훈련할 수 없을까??\n",
    "\n",
    "이런식의 훈련방식을 **점진적 학습**, 온라인 학습 이라고 한다.\n",
    "\n",
    "점진적 학습 알고리즘은 **확률적 경사 하강법**이다.\n",
    "\n",
    "사이킷런에서도 확률적 경사 하강법을 위한 클래스를 제공한다.\n",
    "\n",
    "## 확률적 경사 하강법\n",
    "\n",
    "확률적이란 말은 무작위하게, 랜덤하게의 기술적인 표현이다.\n",
    "\n",
    "경사는 기울기를 말하는 것이다.\n",
    "\n",
    "하강법은 내려가는 방법이다.\n",
    "\n",
    "경사 하강법은 **경사를 따라 내려가는 방법**을 말한다.\n",
    "\n",
    "산에서 내려갈때 가장 빠른 길은 경사가 가장 가파른 길이다.\n",
    "\n",
    "경사 하강법이 이런 방법이다. 가장 가파른 경사를 따라 원하는 지점에 도달하는 것이 목표이다.\n",
    "\n",
    "가장 가파른 길을 내려오지만 **조금씩 내려오는 것**이 중요하다.\n",
    "\n",
    "내려오는 과정이 경사 하강법 모델을 훈련하는 것이다.\n",
    "\n",
    "**확률적**이라는 말은 훈련 세트를 사용하여 가장 가파른 길을 찾는데 딱 하나의 샘플을 훈련세트에서 랜덤하게 골라 가장 가파른 길을 찾는다.\n",
    "\n",
    "랜덤하게 하나의 샘플을 고르는 것이 **확률적 경사 하강법**이다.\n",
    "\n",
    "전체 샘플을 모두 사용할 때까지 계속 반복한다. 그래도 산을 다 내려오지 못한다면? **다시 처음**부터 시작한다.\n",
    "\n",
    "확률적 경사 하강법에서 훈련세트를 한번 모두 사용하는 과정을 **에포크**라고 한다.\n",
    "\n",
    "그러면 하나씩 고르지 말고 여려개의 샘플을 이용해 경사 하강법을 수행할수도 있는데 이를 **미니배치 경사 하강법**이라고 한다.\n",
    "\n",
    "전체 샘플을 사용할 수도 있다. 이를 **배치 경사하강법**이라고 한다.\n",
    "\n",
    "하지만 전체 데이터를 사용하면 컴퓨터 자원을 많이 사용하게 된다.\n",
    "\n",
    "![사진](epoch.jpeg)\n",
    "\n",
    "**확률적 경사 하강법**은 훈련 세트를 사용해 산 아래에 있는 최적의 장소로 조금씩 이동하는 알고리즘이다.\n",
    "\n",
    "그런데 어디서 내려가야 하는 걸까?? 다시 말해서 가장 빠른 길을 찾아 내려가려고 하는 이 산은 도대체 무엇일까??\n",
    "\n",
    "이 산이 **손실 함수**라고 부르는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876c54a",
   "metadata": {},
   "source": [
    "## 손실함수\n",
    "\n",
    "**손실 함수**는 머신러닝 알고리즘이 얼마나 엉터리인지를 측정하는 기준이다\n",
    "\n",
    "하지만 어떤 값이 최솟값인지는 알지 못한다.\n",
    "\n",
    "만족할만한 수준이라면 인정해야 한다.\n",
    ">비용함수는 손실함수의 다른말이다. 엄밀히 말하면 손실함수는 샘플 하나에 대한 손실을 정의하고 비용함수는 훈련 세트에 있는 모든 샘플에 대한 손실 함수의 합을 말한다.\n",
    "\n",
    "분류에서 손실은 정답을 못 맞추는 것이다.\n",
    "\n",
    "만약 그림과 같은 예측과 정답이 있다면?\n",
    "\n",
    "![사진](./target.jpeg)\n",
    "\n",
    "정확도는 4개의 예측 중에 2개만 맞았으므로 정확도는 0.5이다.\n",
    "\n",
    "정확도를 손실 함수로 사용할 수 있을까? 정확도에 음수를 취하면 -1.0이 가장 낮고 -0.0이 가장 높다.\n",
    "\n",
    "하지만 4개의 샘플만 있다면 정확도는 0, 0.25, 0.5, 0.75, 1 다섯 가지뿐이다.\n",
    "\n",
    "산의 경사면은 확실히 연속적이어야 한다!\n",
    "\n",
    "1절의 로지스틱 회귀모델이 확률을 출력하였다 확률은 0~1 사이의 어떤 값도 될 수 있다 즉 연속적이다.\n",
    "\n",
    "## 로지스틱 손실 함수\n",
    "\n",
    "위의 샘플 4개의 예측 확률을 각각 0.9 0.3 0.2 0.8이라고 가정해보자\n",
    "\n",
    "첫번째 샘플의 예측은 0.9이므로 양성 클래스의 타깃인 1과 곱한 다음 음수로 바꿀 수 있다.\n",
    "\n",
    "두번째 샘플의 예측은 0.3이다. 타깃이 양성 클래스(1) 인데 거리가 멀다.\n",
    "\n",
    "예측과 타깃을 곱해 음수로 바꿔보자 -0.3이 되기 때문에 확실히 첫번째 샘플보다 높은 손실이 된다.\n",
    "\n",
    "세번째 샘플은 타깃은 음성 클래스라 0이다. 이 값을 그대로 곱하면 0이되기 때문에 타깃을 마치 양성 클래스 처럼 바꾸어 1로 만든다.\n",
    "\n",
    "대신에 예측값도 양성 클래스에 대한 예측으로 바꾼다. 즉 1 - 0.2 =0.8로 사용한다.\n",
    "\n",
    "그다음 곱하고 음수로 바꾼다.\n",
    "\n",
    "세번째 샘플은 음성 클래스인 타깃을 맞추었으므로 손실이 낮아야 한다. -0.8은 꽤 낮은 손실이다.\n",
    "\n",
    "네번째 샘플도 타깃은 음성 클래스이다. 하지만 정답을 맞히지 못하였다. 타깃을 1로 바꾸고 예측 확률을 1에서 뺀다음 곱해서 음수로 바꿔 보자.\n",
    "\n",
    "네번째 샘플의 손실이 높다.\n",
    "\n",
    "![사진](./example.jpeg)\n",
    "\n",
    "이런 방식으로 계산하면 연속적인 손실 함수를 얻을 수 있을 것같다.\n",
    "\n",
    "여기에서 예측 확률에 로그 함수를 적용하면 더 좋다.\n",
    "\n",
    "예측 확률의 범위는 0~1 사이인데 로그 함수는 이 사이에서 음수가 되므로 최종 손실 값은 양수가 된다.\n",
    "\n",
    "또 로그 함수는 0에 가까울수록 아주 큰 음수가 되기 때문에 손실을 아주 크게 만들어 모델에 큰 영향을 미칠 수 있다.\n",
    "\n",
    "![사진](./log.jpeg)\n",
    "\n",
    "정리하면 위의 그림과 같다.\n",
    "\n",
    "양성 클래스(타깃 = 1)일때 손실은 -log(예측확률)로 계산한다. 확률이 1에서 멀어질수록 손실은 아주 큰 양수가 된다.\n",
    "\n",
    "음성 클래스(타깃 = 0)일때 손실은 -log(1-예측확률)로 계산한다. 예측 확률이 0에서 멀어질수록 손실은 아주 큰 양수가 된다.\n",
    "\n",
    "이 손실 함수를 **로지스틱 손실 함수**라고 부른다 또는 **이진 크로스에트로피 손실 함수**라고도 부른다.\n",
    "\n",
    "다중 분류에서 사용하는 손실 함수를 **크로스엔트로피 손실함수**라고 부른다.\n",
    "\n",
    "이진 분류는 로지스틱 손실 함수를 사용하고 다중 분류는 크로스엔트로피 손실 함수를 사용한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff96d5",
   "metadata": {},
   "source": [
    "## SGDClassifier\n",
    "\n",
    "이번에도 fish_csv_data파일에서 판다스 데이터프레임을 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d03e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fish = pd.read_csv('https://bit.ly/fish_csv_data')\n",
    "\n",
    "# 그다음 Species 열을 제외한 나머지 5개는 입력 데이터로 사용한다.\n",
    "fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy()\n",
    "fish_target = fish['Species'].to_numpy()\n",
    "\n",
    "# 사이킷런의 train_test_split()함수를 사용해 훈련 세트와 테스트 세트로 나눈다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state=42)\n",
    "\n",
    "# 이제 훈련세트와 테스트 세트의 특성을 표준화 전처리 한다.\n",
    "# 꼭 훈련 세트에서 학습한 통계값으로 테스트 세트도 변환해야 한다.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)\n",
    "\n",
    "#사이킷런에서 확률적 경사 하강법을 제공하는 대표적인 분류용 클래스는 SGDClassifier이다.\n",
    "#sklearn.linear_model 패키지 아래에서 임포트 해보자.\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aeb800",
   "metadata": {},
   "source": [
    "SGDClassifier의 객체를 만들때 2개의 매개변수를 지정한다.\n",
    "\n",
    "loss는 손실 함수의 종류를 지정한다. 여기서는 loss='log'로 지정하여 로지스틱 손실 함수를 지정했다.\n",
    "\n",
    "max_iter는 수행할 에포크 횟수를 지정한다. 10으로 지정하여 전체 훈련 세트를 10회 반복한다.\n",
    "\n",
    "그다음 훈련 세트와 테스트 세트에서 정확도 점수를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b96de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773109243697479\n",
      "0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/innoacad06/anaconda3/envs/soum/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sc = SGDClassifier(loss='log', max_iter=10, random_state=42)\n",
    "sc.fit(train_scaled, train_target)\n",
    "print(sc.score(train_scaled, train_target))\n",
    "print(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced3d77",
   "metadata": {},
   "source": [
    "출력된 훈련 세트와 테스트 세트 정확도가 낮다. 아마도 지정한 반복 횟수 10번이 부족해 보인다.\n",
    "\n",
    "확률적 경사 하강법은 점진적 학습이 가능하다. SGDClassifier 객체를 다시 만들지 않고 훈련한 모델 sc를 추가로 더 훈련해 보자.\n",
    "\n",
    "모델을 이어서 훈련할 때는 parial_fit() 매서드를 사용한다.\n",
    "\n",
    "이 메서드는 fit() 메서드와 사용법이 같지만 호출할 때마다 1에포크씩 이어서 훈련할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6966da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151260504201681\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "sc.partial_fit(train_scaled, train_target)\n",
    "print(sc.score(train_scaled, train_target))\n",
    "print(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b08d9ac",
   "metadata": {},
   "source": [
    "아직 점수가 낮지만 정확도가 향상되었다.\n",
    "\n",
    "이 모델을 여러 에포크에서 더 훈련해 볼 필요가 있다. 얼마나 훈련해야 할까? 무작정 많이 반복할 수는 없고 어떤 기준이 필요하다.\n",
    "\n",
    "## 에포크와 과대/과소적합\n",
    "\n",
    "확률적 경사 하강법을 사용한 모델은 에포크 횟수에 따라 과소적합이나 과대적합이 될 수 있다.\n",
    "\n",
    "에포크 횟수가 적으면 모델이 훈련 세트를 덜 학습한다.\n",
    "\n",
    "에포크 획수가 충분히 많으면 훈련 세트를 완전히 학습한다.\n",
    "\n",
    "적은 에포크 횟수는 과소적합된 모델일 가능성이 높다.\n",
    "\n",
    "많은 에포크 횟수는 과대적합된 모델일 가능성이 높다.\n",
    "\n",
    "![사진](./early.jpeg)\n",
    "\n",
    "훈련 세트 점수는 에포크가 진행될수록 꾸준히 증가하지만 테스트 세트 점수는 어느 순간 감소하기 시작한다.\n",
    "\n",
    "이 지점이 과대적합되기 시작하는 곳이다. 과대적합이 시작하기 전에 훈련을 멈추는 것을 **조기 종료**라고 한다.\n",
    "\n",
    "이 예제에서는 fit() 메서드를 사용하지 않고 partial_fit() 메서드만 사용한다.\n",
    "\n",
    "그러면 훈련 세트에 있는 전체 클래스의 레이블을 partial_fit() 메서드에 전달해 주어야 한다.\n",
    "\n",
    "이를 위해 np.unique() 함수로 train_terget에 있는 7개 생선의 목록을 만든다.\n",
    "\n",
    "또 에포크마다 훈련 세트와 테스트 세트에 대한 점수를 기록하기 위해 2개의 리스트를 준비한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54668f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sc = SGDClassifier(loss='log', random_state=42)\n",
    "train_score = []\n",
    "test_score = []\n",
    "classes = np.unique(train_target)\n",
    "\n",
    "# 300번의 에포크 동안 훈련을 반복하여 진행해보자. \n",
    "# 반복마다 훈련 세트와 테스트 세트의 점수를 계산하여 train_score, test_score 리스트에 추가한다.\n",
    "for _ in range(0, 300):\n",
    "    sc.partial_fit(train_scaled, train_target, classes=classes)\n",
    "    train_score.append(sc.score(train_scaled, train_target))\n",
    "    test_score.append(sc.score(test_scaled, test_target))\n",
    "    \n",
    "# 300번의 에포크 동안 기록한 훈련 세트와 테스트 세트의 점수를 그래프로 그려보자\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_score)\n",
    "plt.plot(test_score)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43caf3",
   "metadata": {},
   "source": [
    "그래프를 보니 백 번째 에포크 이후에는 훈련 세트와 테스트 세트의 점수가 조금씩 벌어지고 있다.\n",
    "\n",
    "또 확실히 에포크 초기에는 과소적합되어 훈련세트와 테스트 세트의 점수가 낮다.\n",
    "\n",
    "이 모델의 경우 백 번째 에포크가 적절한 반복 횟수로 보인다.\n",
    "\n",
    "그럼 SGDClassifier의 반복 횟수를 100에 맞추고 모델을 다시 훈련해보자.\n",
    "\n",
    "그리고 최종적으로 훈련 세트와 테스트 세트에서 점수를 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48f64cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957983193277311\n",
      "0.925\n"
     ]
    }
   ],
   "source": [
    "sc = SGDClassifier(loss='log', max_iter=100, tol=None, random_state=42)\n",
    "sc.fit(train_scaled, train_target)\n",
    "print(sc.score(train_scaled, train_target))\n",
    "print(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9257c84a",
   "metadata": {},
   "source": [
    "SGDClassifier의 loss 매개변수를 알아보자.\n",
    "\n",
    "loss 매개변수의 기본값은 'hinge'이다. **힌지 손실**은 **서포트 벡터 머신**이라 불리는 또 다른 머신러닝 알고리즘을 위한 손실 함수이다.\n",
    "\n",
    "서포트 벡터 머신이 널리 사용하는 머신러닝 알고리즘 중 하나, 여러 종류의 손실 함수를 loss 매개변수에 지정하여 다양한 머신러닝 알고리즘을 지원한다.\n",
    "\n",
    "힌지 손실을 사용해 같은 반복 횟수 동안 모델을 훈련해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f93b776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9495798319327731\n",
      "0.925\n"
     ]
    }
   ],
   "source": [
    "sc = SGDClassifier(loss='hinge', max_iter=100, tol=None, random_state=42)\n",
    "sc.fit(train_scaled, train_target)\n",
    "print(sc.score(train_scaled, train_target))\n",
    "print(sc.score(test_scaled, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b00563",
   "metadata": {},
   "source": [
    "## 점진적 학습을 위한 확률적 경사 하강법<문제해결 과정>\n",
    "\n",
    "생선을 실시간으로 학습하기 위한 새로운 머신러닝 모델이 필요하다.\n",
    "\n",
    "**확률적 경사 하강법**을 사용해 점진적으로 학습하는 로지스틱 회귀 모델을 훈련하였다.\n",
    "\n",
    "확률적 경사 하강법은 **손실 함수**라는 산을 정의하고 가장 가파른 경사를 따라 조금씩 내려오는 알고리즘이다.\n",
    "\n",
    "충분히 반복하여 훈련하면 훈련 세트에서 높은 점수를 얻는 모델을 만들 수 있다.\n",
    "\n",
    "훈련을 반복할수록 어느순간 과대적합되고 테스트 세트의 정확도가 줄어든다.\n",
    "\n",
    "지금까지 회귀와 분류에 널리 사용되는 다양한 알고리즘을 배웠다. 이 알고리즘들은 실전에서 널리 사용되는 뛰어난 기법이지만 최고는 아니다.\n",
    "\n",
    "머신러닝에서 가장 뛰어난 성능을 내는 알고리즘이 있다. 다음장에서 이 알고리즘을 배워보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c3caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
